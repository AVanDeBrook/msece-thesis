\documentclass[12pt]{article}

\usepackage{cite}
\usepackage{listings}
\usepackage{multicol}
\usepackage{newtxtext}
\usepackage{setspace}
\usepackage{sectsty}
\usepackage{booktabs}
\usepackage{algpseudocodex}
\usepackage[T1]{fontenc}
\usepackage[numbib]{tocbibind}
\usepackage[lmargin=1.25in,rmargin=1.25in,tmargin=1.0in,bmargin=1.0in]{geometry}

% \settowidth{\parindent}{}

\begin{document}
% Riddle thesis title page
\begin{center}
    \LARGE
    \textbf{
        \textit{
            Language Modeling of Aviation Communications\\
        }
    }

    \vspace*{0.2in}

    \normalsize
    by\\
    \textit{Aaron P.~Van De Brook}\\

    \vspace*{0.25in}

\end{center}
This thesis was prepared under the direction of the candidate's thesis
committee chairman, \underline{Dr.~Jianhua Liu}, Department of \underline{Electrical Engineering \&
    Computer Science}, and has been approved by the members of the thesis committee.
It was submitted to the Department of Electrical Engineering \& Computer Science
and was accepted in partial fulfillment of the requirements for the degree of
Masters of Electrical \& Computer Engineering.

% Signature lines/committee members
\begin{center}
    \begin{minipage}{3in}
        \vspace*{0.25in}
        THESIS COMMITTEE:\\
        \vspace*{0.25in}
        \hrule
        \vspace*{2pt}
        Jianhua Liu, Ph.D.\\
        Committee Chairman\\
        \vspace*{0.75in}
        \hrule
        \vspace*{2pt}
        Prashant Shekhar, Ph.D.\\
        Committee Member\\
        \vspace*{0.75in}
        \hrule
        \vspace*{2pt}
        Andrew Schneider\\
        Committee Member\\
        \vspace*{0.75in}
        \hrule
        \vspace*{2pt}
        Farahzad Behi\\
        Department Chair, Electrical Engineering \& Computer Science\\
        \vspace*{0.75in}
        \hrule
        \vspace*{2pt}
        Associate Vice President for Academics
    \end{minipage}
\end{center}
\newpage
\tableofcontents
\newpage
\doublespacing{}

\section{Abstract}\label{sec:abstract}

\section{Introduction}\label{sec:introduction}
There have been noticeable and significant advancements in the general domain of artificial intelligence recently. Automatic speech recognition and
language modeling technologies, in particular, have made tremendous advances over the past two decades achieving performance levels good enough to
be brought to consumer facing products such as personal assistants, search engines, phones, televisions, etc. Due to the success in the general
domain, applications have begun to spin-off into problem-specific domains, such as (and most notably for this work) aviation. For example, several
speech recognition systems with rule-based natural language inference and semantic extraction algorithms have been implemented at EUROCONTROL
simulation centers across Europe.

At the time of this writing, the current focus of general machine learning algorithms in the automatic speech recognition (ASR) and language modeling
domains has been a mixture of deep learning methods, namely; recurrent, convolutional, and transformer neural networks due to the availability of
large corpora such as LibriSpeech~\cite{panayotov_librispeech_2015} and Mozilla Common Voice~\cite{ardila_common_2020} for ASR and
WikiText~\cite{merity_pointer_2016} and IMDB~\cite{maas_learning_2011} corpora for language modeling. In contrast to the general domain, the aviation
domain still prefers, and sees much success with traditional machine learning models for both ASR and language modeling applications. Typically, the
most prevalent of the traditional models are Hidden Markov models and Gaussian Mixture models, in conjunction with word lattices, N-grams, and/or
rule-based approaches depending on the application and operating environment of the models. The most likely reason for this divergence between the
domains is the difference and relative lack of labeled data in the aviation domain. By comparison, the largest corpus in the general domain is
LibriSpeech with approximately 1000 hours of labeled data whereas, for aviation, the largest corpus is Air Traffic Control Complete with approximately
26 hours of labeled data\footnote{Air Traffic Control Complete has approximately 70 hours of audio data, however, about 26 hours of the 70 are
    labeled.}.



\section{Literature Review}\label{sec:lit_review}
% from thesis proposal; revise and add to this as more references are used
% transformer history (background)
The transformer neural network architecture was proposed in 2017 for Neural Machine Translation tasks and immediately achieved
state-of-the-art (28.4 BLEU on WMT 2014 English-to-German; 41.8 BLEU on WMT English-to-French datasets)\cite{vaswani_attention_2017}. Transformer
architectures have been found to be extremely effective at learning representations and understandings of languages to predict token probabilities as
opposed to transforming one language into another\cite{devlin_bert_2019,liu_roberta_2019}. Transformers have also been found to be very effective at
other NLP-related tasks such as prompt completion and sentiment analysis among others (i.e.~auto-regressive and sequence classification tasks,
respectively)\cite{lewis_bart_2019,radford_improving_2018}.


% ASR context (suggest some need for semi-supervised approaches and therefore LMs)
End-to-end generative models for automatic speech recognition models have made significant progress in recent years with current state-of-the-art
models achieving WERs as low as 2\% on LibriSpeech test sets\cite{han_contextnet_2020,kriman_quartznet_2020,baevski_wav2vec_2020,li_jasper_2019}.
This has led to the development of ASR models for the aviation domain, specifically, in air traffic control communications\cite{badrinath_automatic_2022,smidl_air_2019,zuluaga-gomez_automatic_2020,srinivasamurthy_semi-supervised_2017}. However, due to the lack of
transcribed data in the aviation domain\cite{zuluaga-gomez_automatic_2020,srinivasamurthy_semi-supervised_2017,badrinath_automatic_2022,smidl_air_2019}
ASR models maintain relatively high WERs compared to their counterparts in the more generalized ASR domain\cite{zuluaga-gomez_automatic_2020,badrinath_automatic_2022}. Transfer learning has even yielded limited results in this domain (depending on model
architecture and dataset quality)\cite{badrinath_automatic_2022,zuluaga-gomez_automatic_2020}.


% Unsupervised/semi-supervised in general and LMs commonly used with them
Unsupervised and semi-supervised methodologies have become popular recently in attempts to address limited data availability
and develop new approaches towards modeling human speech (notably, wav2vec has achieved state-of-the-art performance with
very little training data)\cite{baevski_wav2vec_2020,badrinath_automatic_2022,srinivasamurthy_semi-supervised_2017,zuluaga-gomez_contextual_2021}.
Language models are an integral part semi-supervised learning. They are used to obtain a certainty score (or uncertainty
score, as the case may be) for the predicted text, these are usually either word lattices or N-gram models\cite{badrinath_automatic_2022,srinivasamurthy_semi-supervised_2017,zuluaga-gomez_contextual_2021}.
While these have proven to be adequate for most self-supervised learning tasks, they are hardly state-of-the-art.
Wav2vec, the current state-of-the-art unsupervised model (and possibly top performing overall), uses a contrastive process
between convolutional feature extraction and transformer context representations\cite{baevski_wav2vec_2020}.


% LMs and NLP in aero. domain
Various natural language processing methods have been applied to the aviation domain to help deal with miscommunications
and try to mitigate safety incidents\cite{ragnarsdottir_language_2003,tanguy_natural_2016,madeira_machine_2021}.
Some machine learning approaches have been implemented to analyze the text in aviation incident and safety reports to predict
contributing factors and topic models\cite{tanguy_natural_2016,madeira_machine_2021}. An ASR system with NLP post-processing
has also been proposed to analyze Air-Traffic communications and condense significant features (e.g.~weather, runway, and
heading info) into an XML language structure\cite{ragnarsdottir_language_2003}. Transformer language models such as BERT,
RoBERTa, and DeBERTa have been applied to notice to airmen (NOTAM) messages to perform named entity recognition (NER) tasks,
translation tasks (between notations; e.g.~NOTAM notation to Airlang to make parsing tasks easier) and reduce the workload
for pilots during long-haul flights\cite{arnold_knowledge_2022}. Transformer models have also been used for speaker role
identification tasks in the aviation domain (e.g.~identifying pilot versus controller in communications), specifically,
a pretrained BERT model was used and fine-tuned on problem specific data and compared to other models that performed
well at speaker and role identification tasks in general\cite{guo_comparative_2022}.



\section{Data Sources}\label{sec:data_source}
There are four datasets used in this work. The datasets are primarily speech corpora intended either for automatic speech recognition
research in the domain of aviation communications, linguistics research in aviation english, or both. As a result, the text-based data
samples that are used to train the language models in this work are transcripts of aural speech. The datasets used are described in more
detail below. All recordings and transcripts are in english, although there are multiple instances of foreign words occurring

\subsection{Air Traffic Control Complete}\label{sec:atcc}
The Air Traffic Control Complete (ATCC) corpus is a speech corpus consisting of audio recordings with corresponding transcriptions.
ATCC is a collection of three smaller corpora recorded at Dallas-Fort Worth, Logan International, and Washington National airports and
transcribed by subject matter experts (usually controllers and/or pilots) familiar with the terminology specific to their respective
areas\cite{godfrey_air_1994}.

\subsection{ATCO2}\label{sec:atco2}
The ATCO2 dataset is a speech corpus that consists of audio communications at Prague and Brno airports, in Czechia, along with corresponding
transcriptions. The speech recordings and transcripts are crowd sourced from volunteers\cite{szoke_detecting_2021}.


\subsection{Air Traffic Control Simulation}\label{sec:atcosim}
The Air Traffic Control Simulation (ATCOSIM) corpus is a speech corpus consisting of audio recordings and corresponding transcriptions.
The data was recorded at a air traffic control simulation center in Bretigny-sur-Orge, France, specifically the EUROCONTROL Experimental Centre.
In this data, only the controllers' voices are included and therefore the transcripts only include the controller's side of each interaction.
The audio data was transcribed by one person, trained according to the guidelines and formatting requirements of the corpus. After all data was
transcribed, it was reviewed and corrected and any remaining problems were reviewed by an operational air traffic controller and
resolved\cite{hofbauer_atcosim_2008}.

\subsection{ZCU CZ ATC Corpus}\label{sec:zcu_atc}
The ZCU CZ ATC corpus consists of audio recordings and corresponding transcripts in the Czech airspace. Both controller and pilot sides of the
communications are included in this data. Annotations were created by experienced transcribers/annotators and labeled samples were randomly selected
for review during the annotation process. After the dataset was completely labeled, all samples were checked, corrected, and
unified\cite{smidl_air_2019}.

\section{Data Processing}\label{sec:data_processing}
All of the corpora listed above (see~\ref{sec:data_source}) are created at different times, for different purposes, and by different authors.
As a result, the data in these corpora all have different formats and need to be processed into a common format to be used together, with the goal
being to essentially create a ``super-corpus'' that includes all the corpora listed above (i.e., a superset of the other corpora).

All data was processed in Python using primarily built-in functions/modules\footnote{The \lstinline|re| and \lstinline|xml| modules were also used
    although these are built into most Python distributions by default.}. The text data is extracted from the corpus transcripts parsing from the
corpora-specific formats where necessary i.e.~Lisp in ATCC, XML in ATCO2 and ZCU CZ ATC, and plain text in ATCOSIM, the transcriber annotations
are removed where necessary\footnote{A copy of the original data is made, then the annotations are removed from the copy.}, and the resulting text
is written to a file in the standard corpus format (an ASCII text file with one line in the file corresponding to one sample from the corpus) to a
file.

\subsection{Handling Spelling Errors \& Inconsistencies}\label{sec:spelling_errors}
By the nature of the data labeling process, there are bound to be spelling errors introduced by the annotators during corpora creation. This gets
exacerbated by the aggregation of several corpora with varying controls for correcting spelling errors and inconsistencies. Nearly all of the errors
are recoverable/correctable given context. For example, ``possibility of \textbf{tornado's}'' should clearly have been
``possibility of \textbf{tornadoes}'', changing the possessive form of ``tornado'' to the plural form. There are also instances of spelling conventions
that are consistent within corpora, but become inconsistent when the corpora are combined.

% 22 spelling errors
Manually reviewing every sample in the corpus is unrealistic considering that there are over 50,000 data samples and would be subject the same
human error that introduced those errors in the first place. Instead, the frequency of occurrence of tokens in the corpora combined with manual review
thereafter, was used to detect and correct the most common errors. Tokens with the lowest frequency across corpora were manually reviewed and
corrected where necessary. An \(A \rightarrow B\) mapping system was used to correct the errors, where \(A\) is the erroneous token and \(B\) is the
corrected or replaced token. A total of 22 unique errors were detected and subsequently corrected or removed using this method, although multiple
instances of those errors typically occurred.

% hesitations, cut off words, different kinds of filled pauses
The mapping system described above is also used to modify within corpora conventions to be consistent across corpora. Three areas are addressed here:
hesitations, cut-off or partial words, and filled pauses within speech. These areas are defined differently between the four corpora, which makes
unifying the transcripts difficult. Hesitations, for example, are defined by one corpus as any incomplete or non-english speech sounds and left
completely undefined by another (despite annotators making notes about hesitations). The way in which hesitations, pauses, and partial words are
transcribed differs between corpora as well. Two corpora prescribe special tokens to these phenomena such as ``[hes]'', ``[hesitation]'', ``<pause>'',
or similar, while the others transcribe the data as it sounds (i.e., ``uh'', ``eh'', or ``er'' for filled pauses and ``cir-'' or ``cir+'' for
instances that were cut-off mid pronunciation). In order to facilitate the unification of the transcripts for all four corpora, the conventions for
transcribing these phenomena are redefined below:

\begin{table}[h!]
    \centering
    \begin{tabular}{l p{0.65\linewidth}}
        \toprule
        Phenomenon               & Definition                                                                                                              \\
        \midrule
        Hesitations              & Instances of hesitation for which the specific realization is not defined (usually some special token is used instead). \\
        \midrule
        Partial \& cut-off words & Partially pronounced words are indicated by a hyphen character where the pronunciation of the word is missing.          \\
        \midrule
        Filled pauses            & Hesitations with a verbal component that has been described or otherwise defined by the corpus/annotator.               \\
        \bottomrule
    \end{tabular}
    \label{tab:phenomena_definitions}
    \caption{Speech/transcription phenomena with corresponding convention for transcribing or translating, depending on the corpus being processed.}
\end{table}



\begin{table}[h!]
    \centering
    \begin{tabular}{l l}
        \toprule
        Phenomenon                   & Convention for representation \\
        \midrule
        Hesitations                  & [HES]                         \\
        \midrule
        Partial \& cut-off words     & -                             \\
        \midrule
        Filled pauses (open-mouth)   & uh, um, ah                    \\
        \midrule
        Filled pauses (closed-mouth) & hm, mhm                       \\
        \bottomrule
    \end{tabular}
    \label{tab:phenomena_conventions}
    \caption{Conventions for transcript representation/translation of phenomena to keep transcripts consistent across corpora.}
\end{table}

A special token is used to represent hesitations when no other context regarding the realization of hesitation is present. If other corpora use a
special token to represent hesitations, it is translated to match the convention in table~\ref{tab:phenomena_conventions}. Partial/cut-off words
are represented with a hyphen (-) at the point where the pronounced word is cut off. For example, if the last syllable of ``approaching'' is cut
mid transmission, it would be represented in the transcript as ``approa-'' or, likewise, if the first syllable is cut off, it would be written as
``-roaching''. Lastly, if there is enough information in the original transcript to indicate the realization of a hesitation, it is represented by
the most appropriate token from ``Filled pauses'' in table~\ref{tab:phenomena_conventions}.

\section{Data Analysis}\label{sec:data_analysis}
% sequence lengths, unique tokens, total number of tokens, total number of samples, breakdown by each dataset
Relevant corpora statistics were observed or calculated and are presented in Table~\ref{table:corpora_stats}. This includes the number of samples in
the corpus, mean sequence length per sample in the corpus, the number of unique tokens in the corpus, and the total number of tokens in the corpus.
The same statistics were also calculated across corpora, since all four corpora will be combined for training and testing the language and speech
recognition models. Note that this is based on the raw data after loading and unifying the corpora, prior to preprocessing for model training/testing
and outlier removal.


\begin{table}[h!]
    \centering
    \begin{tabular}{l r r r r}
        \toprule
        \textbf{Corpus} & \textbf{Samples} & \textbf{Mean Sequence Length (\(\pm \sigma\))} & \textbf{Unique Tokens} & \textbf{Tokens} \\
        \midrule
        ATCC            & 29,862           & \(11.90 \pm 7.22\)                             & 2,209                  & 355,473         \\
        ATCO2           & 874              & \(12.28 \pm 4.12\)                             & 786                    & 10,733          \\
        ATCOSIM         & 9,544            & \(11.23 \pm 4.12\)                             & 823                    & 107,153         \\
        ZCU CZ ATC      & 14,435           & \(10.05 \pm 5.50\)                             & 2,983                  & 145,107         \\
        \midrule
        Total           & 54,715           & \(11.30 \pm 6.36\)                             & 5,040                  & 618,466         \\
        \bottomrule
    \end{tabular}
    \label{table:corpora_stats}
    \caption{The number of samples, mean sequence length, number of unique tokens, and total number of tokens by corpus, including the cumulative
        total across all corpora.}
\end{table}

The ATCC and ZCU CZ ATC corpora make up a significant portion of the data, ATCC alone makes up more than half (approximately 54\%) of the combined
data, and ATCC and ZCU CZ ATC together make up approximately 81\% of the data. The sequence lengths of the samples are fairly consistent across
corpora with at most about an 18\% percent difference between sequence lengths. The number of unique tokens does not scale additively to the
combined corpora, which is as expected. Considering that aviation English generally conforms to and follows ICAO phraseology standards we would expect
that many terms would be shared across corpora with the exception of geographic/location specific terms, such as city, landmark, airport, and airline
names, etc.~that typically vary across regions.

\subsection{Outlier Detection and Analysis}\label{sec:outliers}
The Local Outlier Factor (LOF) algorithm~\cite{breunig_lof_2000} was used to detect and remove outliers in the corpora for further analysis. The
sequence lengths of the data samples were used to determine outliers. Since all four corpora are aggregated, LOF analysis was performed on the
aggregated data instead of on the individual corpora.

Sci-Kit Learn's implementation of the LOF
algorithm was used with a value of \(N = 35\) for \(N\) neighbors in the K-Nearest Neighbors algorithm and Minkowski distance for distance
metrics/calculations (in this case, since \(p=2\), Euclidean distance is effectively used for distance calculations). A total of 47 samples were
detected as outliers and removed for analysis and are summarized in table~\ref{table:outlier_stats}.

\begin{table}[h!]
    \centering
    \begin{tabular}{l | r}
        \toprule
        \multicolumn{2}{c}{Outlier Properties}   \\
        \midrule
        \textbf{Mean Sequence Length}    & 47.30 \\
        \textbf{Std of Sequence Length}  & 11.82 \\
        \textbf{Minimum Sequence Length} & 38    \\
        \textbf{Maximum Sequence Length} & 73    \\
        \textbf{\# Samples}              & 47    \\
        \bottomrule
    \end{tabular}
    \label{table:outlier_stats}
    \caption{Mean, standard deviation, minimum, and maximum sequence length of samples detected as outliers.}
\end{table}

Although all of the outliers have higher sequence lengths than the typical sequence lengths of the other samples in the data, going the through
the outlying samples manually and reviewing each reveals that, for the most part, the samples are typical albeit somewhat complex communications.
With the exception of four outliers, all of the samples labeled as outlying by the LOF algorithm were kept in the data.

\section{Language Modeling}
% bert, roberta
% ngram
This section introduces the chosen language model architectures as well as their pretrained checkpoints, if one is used. Two transformer-based
architectures are used, BERT and RoBERTa, and statistical/machine learning-based approaches such as N-gram and word lattices.

The transformers are pre-trained using the same masked language modeling (MLM) objective presented in Devlin et al.~\cite{devlin_bert_2019} to train
BERT for bidirectional encoding representation and likewise in Liu et al.~for training RoBERTa~\cite{liu_roberta_2019}. Given the results of the
RoBERTa pretraining and downstream task training thereafter~\cite{liu_roberta_2019}, it was initially decided to eliminate the next sentence prediction
(NSP) task as it was used in BERT, however, their results suggest that the success of the MLM-only approach was due to the increase in batch and
overall data size~\cite{liu_roberta_2019}. Taking this into account, along with the very limited amount of data available in the domain of aviation
an NSP pretraining task was implemented where possible\footnote{Only about half of the data (ATCC) is in a format that enables us to extract the turn
    taking phenomenon that is present in most air-traffic communications.} to improve its pretraining results.



\section{Speech Recognition}


\section{Tokenization Algorithms}
% present and explain the tokenization algorithms used (possibly which models they correspond to)
Tokenization is the process of separating or segmenting samples into tokens. The rules by which the tokens are created or segmented depends entirely
on the algorithm used. The simplest and most intuitive way to do this by creating tokens based on whitespace i.e., each ``word'' in the corpus
is treated as a token\footnote{The Huggingface Tokenizer library implements this as the \lstinline|WordLevel| tokenizer.}. Although this is a simple
and easy to understand method of tokenization, it does little to nothing to address the out-of-vocabulary problem that necessarily comes with any
NLP tasks~\cite{wu_googles_2016}.

\subsection{WordPiece}


\subsection{(Byte-Level) Byte-Pair Encoding}


\newpage
\bibliography{refs}
\bibliographystyle{plain}

\end{document}
