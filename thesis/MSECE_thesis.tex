\documentclass[12pt]{article}

\usepackage{cite}
\usepackage{listings}
\usepackage{multicol}
\usepackage{newtxtext}
\usepackage{setspace}
\usepackage{sectsty}
\usepackage{booktabs}
\usepackage[T1]{fontenc}
\usepackage[numbib]{tocbibind}
\usepackage[lmargin=1.25in,rmargin=1.25in,tmargin=1.0in,bmargin=1.0in]{geometry}

% \settowidth{\parindent}{}

\begin{document}
% Riddle thesis title page
\begin{center}
    \LARGE
    \textbf{
        \textit{
            Language Modeling of Aviation Communications\\
        }
    }

    \vspace*{0.2in}

    \normalsize
    by\\
    \textit{Aaron P.~Van De Brook}\\

    \vspace*{0.25in}

\end{center}
This thesis was prepared under the direction of the candidate's thesis
committee chairman, \underline{Dr.~Jianhua Liu}, Department of \underline{Electrical Engineering \&
    Computer Science}, and has been approved by the members of the thesis committee.
It was submitted to the Department of Electrical Engineering \& Computer Science
and was accepted in partial fulfillment of the requirements for the degree of
Masters of Electrical \& Computer Engineering.

% Signature lines/committee members
\begin{center}
    \begin{minipage}{3in}
        \vspace*{0.25in}
        THESIS COMMITTEE:\\
        \vspace*{0.25in}
        \hrule
        \vspace*{2pt}
        Jianhua Liu, Ph.D.\\
        Committee Chairman\\
        \vspace*{0.75in}
        \hrule
        \vspace*{2pt}
        Prashant Shekhar, Ph.D.\\
        Committee Member\\
        \vspace*{0.75in}
        \hrule
        \vspace*{2pt}
        Andrew Schneider, Ph.D.\\
        Committee Member\\
        \vspace*{0.75in}
        \hrule
        \vspace*{2pt}
        Farahzad Behi\\
        Department Chair, Electrical Engineering \& Computer Science\\
        \vspace*{0.75in}
        \hrule
        \vspace*{2pt}
        Associate Vice President for Academics
    \end{minipage}
\end{center}
\newpage
\tableofcontents
\newpage
\doublespacing{}

\section{Abstract}\label{sec:abstract}

\section{Introduction}\label{sec:introduction}

\section{Literature Review}\label{sec:lit_review}
% from proposal; revise and add to this as more references are used
% transformer history
The transformer neural network architecture was proposed in 2017 for Neural Machine Translation tasks and immediately achieved
state-of-the-art (28.4 BLEU on WMT 2014 English-to-German; 41.8 BLEU on WMT English-to-French datasets)\cite{vaswani_attention_2017}. Transformer
architectures have been found to be extremely effective at learning representations and understandings of languages to predict token probabilities as
opposed to transforming one language into another\cite{devlin_bert_2019,liu_roberta_2019}. Transformers have also been found to be very effective at
other NLP-related tasks such as prompt completion and sentiment analysis among others (i.e.~auto-regressive and sequence classification tasks,
respectively)\cite{lewis_bart_2019,radford_improving_2018}.


% ASR context (suggest some need for semi-supervised approaches and therefore LMs)
End-to-end generative models for automatic speech recognition models have made significant progress in recent years with current state-of-the-art
models achieving WERs as low as 2\% on LibriSpeech test sets\cite{han_contextnet_2020,kriman_quartznet_2020,baevski_wav2vec_2020,li_jasper_2019}.
This has led to the development of ASR models for the aviation domain, specifically, in air traffic control communications\cite{badrinath_automatic_2022,smidl_air_2019,zuluaga-gomez_automatic_2020,srinivasamurthy_semi-supervised_2017}. However, due to the lack of
transcribed data in the aviation domain\cite{zuluaga-gomez_automatic_2020,srinivasamurthy_semi-supervised_2017,badrinath_automatic_2022,smidl_air_2019}
ASR models maintain relatively high WERs compared to their counterparts in the more generalized ASR domain\cite{zuluaga-gomez_automatic_2020,badrinath_automatic_2022}. Transfer learning has even yielded limited results in this domain (depending on model
architecture and dataset quality)\cite{badrinath_automatic_2022,zuluaga-gomez_automatic_2020}.


% Unsupervised/semi-supervised in general and LMs commonly used with them
Unsupervised and semi-supervised methodologies have become popular recently in attempts to address limited data availability
and develop new approaches towards modeling human speech (notably, wav2vec has achieved state-of-the-art performance with
very little training data)\cite{baevski_wav2vec_2020,badrinath_automatic_2022,srinivasamurthy_semi-supervised_2017,zuluaga-gomez_contextual_2021}.
Language models are an integral part semi-supervised learning. They are used to obtain a certainty score (or uncertainty
score, as the case may be) for the predicted text, these are usually either word lattices or N-gram models\cite{badrinath_automatic_2022,srinivasamurthy_semi-supervised_2017,zuluaga-gomez_contextual_2021}.
While these have proven to be adequate for most self-supervised learning tasks, they are hardly state-of-the-art.
Wav2vec, the current state-of-the-art unsupervised model (and possibly top performing overall), uses a contrastive process
between convolutional feature extraction and transformer context representations\cite{baevski_wav2vec_2020}.


% LMs and NLP in aero. domain
Various natural language processing methods have been applied to the aviation domain to help deal with miscommunications
and try to mitigate safety incidents\cite{ragnarsdottir_language_2003,tanguy_natural_2016,madeira_machine_2021}.
Some machine learning approaches have been implemented to analyze the text in aviation incident and safety reports to predict
contributing factors and topic models\cite{tanguy_natural_2016,madeira_machine_2021}. An ASR system with NLP post-processing
has also been proposed to analyze Air-Traffic communications and condense significant features (e.g.~weather, runway, and
heading info) into an XML language structure\cite{ragnarsdottir_language_2003}. Transformer language models such as BERT,
RoBERTa, and DeBERTa have been applied to notice to airmen (NOTAM) messages to perform named entity recognition (NER) tasks,
translation tasks (between notations; e.g.~NOTAM notation to Airlang to make parsing tasks easier) and reduce the workload
for pilots during long-haul flights\cite{arnold_knowledge_2022}. Transformer models have also been used for speaker role
identification tasks in the aviation domain (e.g.~identifying pilot versus controller in communications), specifically,
a pretrained BERT model was used and fine-tuned on problem specific data and compared to other models that performed
well at speaker and role identification tasks in general\cite{guo_comparative_2022}.

\section{Data Sources}\label{sec:data_source}
There are four datasets used in this work. The datasets are primarily speech corpora intended either for automatic speech recognition
research in the domain of aviation communications, linguistics research in aviation english, or both. As a result, the text-based data
samples that are used to train the language models in this work are transcripts of aural speech. The datasets used are described in more
detail below. All recordings and transcripts are in english, although there are multiple instances of foreign words occuring

\subsection{Air Traffic Control Complete}\label{sec:atcc}
The Air Traffic Control Complete (ATCC) corpus is a speech corpus consisting of audio recordings with corresponding transcriptions.
ATCC is a collection of three smaller corpora recorded at Dallas-Fort Worth, Logan International, and Washington National airports and
transcribed by subject matter experts (usually controllers and/or pilots) familiar with the terminology specific to their respective
areas\cite{godfrey_air_1994}.

\subsection{ATCO2}\label{sec:atco2}
The ATCO2 dataset is a speech corpus that consists of audio communications at Prague and Brno airports, in Czechia, along with corresponding
transcriptions. The speech recordings and transcripts are crowd sourced from volunteers\cite{szoke_detecting_2021}.


\subsection{Air Traffic Control Simulation}\label{sec:atcosim}
The Air Traffic Control Simulation (ATCOSIM) corpus is a speech corpus consisting of audio recordings and corresponding transcriptions.
The data was recorded at a air traffic control simulation center in Bretigny-sur-Orge, France, specifically the EUROCONTROL Experimental Centre.
In this data, only the controllers' voices are included and therefore the transcripts only include the controller's side of each interaction.
The audio data was transcribed by one person, trained according to the guidelines and formatting requirements of the corpus. After all data was
transcribed, it was reviewed and corrected and any remaining problems were reviewed by an operational air traffic controller and
resolved\cite{hofbauer_atcosim_2008}.

\subsection{ZCU CZ ATC Corpus}\label{sec:zcu_atc}
The ZCU CZ ATC corpus consists of audio recordings and corresponding transcripts in the Czech airspace. Both controller and pilot sides of the
communications are included in this data. Annotations were created by experienced transcribers/annotators and labeled samples were randomly selected
for review during the annoation process. After the dataset was completely labeled, all samples were checked, corrected, and
unified\cite{smidl_air_2019}.

\section{Data Processing}\label{sec:data_processing}
All of the corpora listed above (see~\ref{sec:data_source}) are created at different times, for different purposes, and by different authors.
As a result, the data in these corpora all have different formats and need to be processed into a common format to be used together, with the goal
being to essentially create a ``super-corpus'' that includes all the corpora listed above (i.e., a superset of the other corpora).

All data was processed in Python using primarily built-in functions/modules\footnote{The \lstinline|re| and \lstinline|xml| modules were also used
    although these are built into most Python distributions by default.}. The text data is extracted from the corpus transcripts parsing from the
corpora-specific formats where necessary i.e.~Lisp in ATCC, XML in ATCO2 and ZCU CZ ATC, and plain text in ATCOSIM, the transcriber annotations
are removed where necessary\footnote{A copy of the original data is made, then the annotations are removed from the copy.}, and the resulting text
is written to a file in the standard corpus format (an ASCII text file with one line in the file corresponding to one sample from the corpus) to a
file.

\subsection{Handling Spelling Errors \& Inconsistencies}\label{sec:spelling_errors}
By the nature of the data labeling process, there are bound to be spelling errors introduced by the annotators during corpora creation. This gets
exacerbated by the aggregation of several corpora with varying controls for correcting spelling errors and inconsistencies. Nearly all of the errors
are recoverable/correctable given context. For example, ``possibility of \textbf{tornado's}'' should clearly have been
``possibility of \textbf{tornadoes}'', changing the posessive form of ``tornado'' to the plural form. There are also instances of spelling conventions
that are consistent within corpora, but become inconsistent when the corpora are combined.

% 22 spelling errors
Manually reviewing every sample in the corpus is unrealistic considering that there are over 50,000 data samples and would be subject the same
human error that introduced those errors in the first place. Instead, the frequency of occurence of tokens in the corpora combined with manual review
thereafter, was used to detect and correct the most common errors. Tokens with the lowest frequency across corpora were manually reviewed and
corrected where necessary. An \(A \rightarrow B\) mapping system was used to correct the errors, where \(A\) is the erroneous token and \(B\) is the
corrected or replaced token. A total of 22 unique errors were detected and subsequently corrected or removed using this method.

% hesitations, cut off words, different kinds of filled pauses
The mapping system described above is also used to modify within corpora conventions to be consistent across corpora. Three areas are addressed here:
hesitations, cut-off or partial words, and filled pauses within speech. These areas are defined differently between the four corpora, which makes
unifying the transcripts difficult. Hesitations, for example, are defined by one corpus as any incomplete or non-english speech sounds and left
completely undefined by another (despite annotators making notes about hesitations). The way in which hesitations, pauses, and partial words are
transcribed differs between corpora as well. Two corpora prescribe special tokens to these phenomena such as ``[hes]'', ``[hesitation]'', ``<pause>'',
or similar, while the others transcribe the data as it sounds (i.e., ``uh'', ``eh'', or ``er'' for filled pauses and ``cir-'' or ``cir+'' for
instances that were cut-off mid pronunciation). In order to facilitate the unification of the transcripts for all four copora, all three of these
phenomena have been redefined with accompanying translation/replacement rules below:

\section{Data Analysis}\label{sec:data_analysis}
% sequence lengths, unique tokens, total number of tokens, total number of samples, breakdown by each dataset
Relevant corpora statistics were observed or calculated are are presented in Table~\ref{table:corpora_stats}. This includes the number of samples in
the corpus, mean sequence length per sample in the corpus, the number of unique tokens in the corpus, and the total number of tokens in the corpus.
The same statistics were also calculated across corpora, since all four corpora will be combined for training and testing the language and speech
recognition models. Note that this is based on the raw data after loading and unifying the corpora, prior to preprocessing for model training/testing
and outlier removal.


\begin{table}[h!]
    \centering
    \begin{tabular}{l r r r r}
        \toprule
        \textbf{Corpus} & \textbf{Samples} & \textbf{Mean Sequence Length (\(\pm \sigma\))} & \textbf{Unique Tokens} & \textbf{Tokens} \\
        \midrule
        ATCC            & 29,862           & \(11.90 \pm 7.22\)                             & 2,209                  & 355,473         \\
        ATCO2           & 874              & \(12.28 \pm 4.12\)                             & 786                    & 10,733          \\
        ATCOSIM         & 9,544            & \(11.23 \pm 4.12\)                             & 823                    & 107,153         \\
        ZCU CZ ATC      & 14,435           & \(10.05 \pm 5.50\)                             & 2,983                  & 145,107         \\
        \midrule
        Total           & 54,715           & \(11.30 \pm 6.36\)                             & 5,040                  & 618,466         \\
        \bottomrule
    \end{tabular}
    \label{table:corpora_stats}
    \caption{The number of samples, mean sequence length, number of unique tokens, and total number of tokens by corpus, including the cumulative
        total across all corpora.}
\end{table}

The ATCC and ZCU CZ ATC corpora make up a significant portion of the data, ATCC alone makes up more than half (approximately 54\%) of the combined
data, and ATCC and ZCU CZ ATC together make up aprroximately 81\% of the data. The sequence lengths of the samples are fairly consistent across
corpora with at most about an 18\% percent difference between sequence lengths. The number of unique tokens does not scale additively to the
combined corpora, which is as expected. Considering that aviation English generally conforms to and follows ICAO phraseology standards we would expect
that many terms would be shared across corpora with the exception of geographic/location specific terms, such as city, landmark, airport, and airline
names, etc.~that typically vary across regions.

\subsection{Outlier Detection and Analysis}\label{sec:outliers}
The Local Outlier Factor (LOF) algorithm~\cite{breunig_lof_2000} was used to detect and remove outliers in the corpora for further analysis. The
sequence lengths of the data samples were used to determine outliers. Since all four corpora are aggregated, LOF analysis was performed on the
aggregated data instead of on the individual corpora.

Sci-Kit Learn's implementation of the LOF
algorithm\footnote{https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html\#sklearn-neighbors-localoutlierfactor}
was used with a value of \(N = 35\) for \(N\) neighbors in the K-Nearest Neighbors algorithm and Minkowski distance for distance metrics/calculations
(in this case, since \(p=2\), Euclidean distance is effectively used for distance calculations). A total of 47 samples were detected as outliers and
removed for analysis and are summarized in table~\ref{table:outlier_stats}.

\begin{table}[h!]
    \centering
    \begin{tabular}{l | r}
        \toprule
        \multicolumn{2}{c}{Outlier Properties}   \\
        \midrule
        \textbf{Mean Sequence Length}    & 47.30 \\
        \textbf{Std of Sequence Length}  & 11.82 \\
        \textbf{Minimum Sequence Length} & 38    \\
        \textbf{Maximum Sequence Length} & 73    \\
        \textbf{\# Samples}              & 47    \\
        \bottomrule
    \end{tabular}
    \label{table:outlier_stats}
    \caption{Mean, standard deviation, minimum, and maximum sequence length of samples detected as outliers.}
\end{table}

Although all of the outliers have higher sequence lengths than the typical sequence lengths of the other samples in the data, going the through
the outlying samples manually and reviewing each reveals that, for the most part, the samples are typical albeit somewhat complex communications.
With the exception of four outliers, all of the samples labeled as outlying by the LOF algorithm were kept in the data.

\subsection{Data Preprocessing}
% explain and justify what is removed from the text, how, and why
% present and explain any relevant algorithms where necessary


\subsection{Tokenization}
% present and explain the tokenization algorithms used (possibly which models they correspond to)

\newpage
\bibliography{refs}
\bibliographystyle{plain}

\end{document}
